# -*- coding: utf-8 -*-
"""AirBnB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i5BGeareeBT0iu3GTkMJeLAiYc6HWz9c

#Intro:
In this project, I will be analyzing data from AirBnB. I will be looking at the data for Seattle and Boston and address three key questions with the data using the CRISP-DM Process (Cross Industry Process for Data Mining)

#CRISP-DM
**Business Understanding** <br>
I will be evaluating the data for my company that uses Airbnb services a lot for our workers who travel often. Since we are a startup, we are on a budget. They assigned me the task of analyzing the data and determine when and were would be the best time and place to book on Airbnb. <br>
**Question 1:** 
Our first question to address is does the season / month effect the price of listing? If so, which season / month is the most profitable? Which ones are least profitable?

##Data Understanding
**Gathering Data:**
"""

import pandas as pd
import plotly.graph_objects as go

boston_calendar = pd.read_csv('boston_calendar.csv')
seattle_calendar = pd.read_csv('seattle_calendar.csv')

#Function for displaying Pie Chart
def pie_chart(labels, values, title):
  """
  This function is used to create a pie chart.

  Arguments:
      labels: the items that you are graphing
      values: the values of the items you are graphing
      title: string of title for the pie chart

  Returns:
      None
  """
  fig = go.Figure(data=[go.Pie(labels=labels, values=values, textinfo='label+percent')])
  fig.update_layout(title={'text':title,
                          'y':0.9,'x':.61,
                          'xanchor': 'right'})
  fig.show()

"""##Preparing Data
**Assessing Data:**
"""

boston_calendar.info()

seattle_calendar.info()

boston_calendar.head()

"""Result: The data for this one is pretty straight forward. We are only interest in the data where there is availibility, which therefore is associated with a price.

**Cleaning Data:**
"""

# Add location column to Boston dataframe
boston_calendar['location'] = 'Boston'
boston_calendar

# Add location column to Seattle dataframe
seattle_calendar['location'] = 'Seattle'
seattle_calendar

# Append both calendars together into one dataframe
calendar = boston_calendar.append(seattle_calendar)
calendar

# Create month column from date
calendar['month'] = pd.DatetimeIndex(calendar['date']).month
calendar

# Remove all symbols from price
calendar['price'] = calendar['price'].str.replace(r'\D', '')

# Drop all nan since they were not listed and convert price to int
calendar.dropna(axis=0, subset=['price'], inplace=True)
calendar['price'] = calendar['price'].astype(int)
calendar

# Divide by 100 to convert cents to dollar
calendar['price'] = calendar['price'] / 100
calendar

# Find average price of listing per month for both locations
seattle_month_price = calendar[calendar['location']== 'Seattle'].groupby('month')['price'].mean()
boston_month_price = calendar[calendar['location']== 'Boston'].groupby('month')['price'].mean()

seattle_month_price

boston_month_price

"""##Data Modeling:"""

pd.concat({
    'Seattle': seattle_month_price, 'Boston': boston_month_price
}, axis=1).plot.bar();

"""##Evaluate Results <br>
Price flucuates through the year for both locations.

For Seattle, the winter months of Jan and Feb are the least profitable, while the summer months of June through August are the most profitable. Seattle lowest average price is &dollar;123 per listing in January and a high of &dollar;152 per listing in July.

For Boston, the winter months of Jan to Feb are the least profitable, while the fall months of Sept through Oct are the most profitable. Boston lowest average price is &dollar;182 per listing in Feburary and &dollar;237 per listing in September.

##Deploy
In making a financial business decision of when to list a property, it is recommended to list during peak season, which is July in Seattle and September in Boston.

#CRISP-DM
**Business Understanding** <br>
#Question 2: <br>
What percentage of the different types of listing on AirBnB?  Is there a property type that needs business focus?

##Data Understanding
**Gathering Data:**
"""

seattle_listing = pd.read_csv('seattle_listings.csv')
boston_listing = pd.read_csv('boston_listings.csv')

"""##Preparing Data
**Assessing Data:**
"""

seattle_listing.info()

#For this question, we only need to look at the property type, so we will only use the column
seattle_listing = seattle_listing[['id', 'property_type']]
seattle_listing

#Assess the data
seattle_listing.info()

"""**Cleaning Data:**"""

#Drop the one line that contains Null values
seattle_listing.dropna(inplace=True)
seattle_listing.info()

#Get values of the different property types
seattle_listing.property_type.value_counts()

#Create dictionary for convert Property types to 3 unique value. 
#House and Townhouse are consider both houses, except townhouse shares a wall
#Condo's and apartments are the same. The only difference is ownership
#The rest are considered 'Others'
rooms = {'Townhouse': 'House',
         'Condominium': 'Apartment',
         'Loft': 'Other',
         'Bed & Breakfast': 'Other',
         'Cabin': 'Other',
         'Camper/RV': 'Other',
         'Bungalow': 'Other',
         'Boat': 'Other',
         'Tent': 'Other',
         'Treehouse': 'Other',
         'Dorm': 'Other',
         'Chalet': 'Other',
         'Yurt': 'Other',
         'Entire Floor': 'Other',
         'Villa': 'Other',
         'Guesthouse': 'Other'}
seattle_listing.replace({'property_type':rooms}, inplace=True)
seattle_listing.property_type.value_counts()

#Calculate total number of listing
total_listing = len(seattle_listing)

#Convert value counts to percentage by dividing by total counts
seattle_prop = seattle_listing.property_type.value_counts()
seattle_prop = seattle_prop / total_listing
seattle_prop

"""##Data Modeling:"""

pie_chart(seattle_prop.index, seattle_prop.values, 'Seattle AirBnB Property Types')

"""##Preparing Data
**Assessing Data:**
"""

#Repeat process for Boston
boston_listing = boston_listing[['id', 'property_type']]
boston_listing.property_type.value_counts()

boston_listing.info()

"""**Cleaning Data:**"""

boston_listing.dropna(inplace=True)
boston_listing.info()

#Convert property types to 3 different categories: House, Apartment, Other
boston_listing.replace({'property_type':rooms}, inplace=True)
boston_listing.property_type.value_counts()

#Calculate total number of listing
total_listing = len(boston_listing)
total_listing

#Convert value counts to percentage by dividing by total counts
boston_prop = boston_listing.property_type.value_counts()
boston_prop = boston_prop / total_listing
boston_prop

"""##Data Modeling:"""

pie_chart(boston_prop.index, boston_prop.values, 'Boston AirBnB Property Types')

"""##Evaluate Results
Seattle and Boston are vastly different when it comes to the make up of property types. For Seattle, it is about equally the same in terms of the percentage of Home and Apartment listings, with both around 48% each, while only 4% falls under the category of other.  As for Boston, also 80% of the listing are Apartments. Only 17% falls under the House property type. That is much lower than Seattle.

##Deploy
Both locations has around 96% of their properties that are listing as either Homes or Apartments.  Seattle has a even split between homes and apartments, while Boston has a low percentage of home listing. There could be business opportunties for getting more homes listed on Airbnb. Also, Airbub has a large potentional market for listings that are not your tradition homes and apartments. Things like treehouse, yurt, Rv's could be used to attract more customers.

#CRISP-DM
**Business Understanding** <br>
#Question 3: <br>
What factors effects the price of the listing?

##Data Understanding
**Gathering Data:**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import seaborn as sns
# %matplotlib inline

seattle_listing = pd.read_csv('seattle_listings.csv')
seattle_listing.info()

"""##Preparing Data
**Assessing Data:**
"""

seattle_listing.head()

"""**Cleaning Data**"""

#Select some potential factors that may effect the price of listing
seattle_price = seattle_listing[['id', 'bedrooms', 'bathrooms', 'review_scores_rating', 'price']]
seattle_price

seattle_price.info()

# Remove all symbols from price
seattle_price['price'] = seattle_price['price'].str.replace(r'\D', '')
seattle_price['price'] = seattle_price['price'].astype(int)
seattle_price['price'] = seattle_price['price'] / 100

#Fill NaN values with the mean value of the column
fill_mean = lambda col: col.fillna(col.mean())

seattle_price = seattle_price.apply(fill_mean, axis=0)
seattle_price.info()

seattle_price

seattle_price.hist();

"""##Data Modeling:"""

#Look at some potential correlation between Price and other factors
sns.heatmap(seattle_price.corr(), annot=True, fmt=".2f");

#Split into explanatory and response variables
X = seattle_price[['bedrooms', 'bathrooms', 'review_scores_rating']]
y = seattle_price['price']

#Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42) 

lm_model = LinearRegression(normalize=True) # Instantiate
lm_model.fit(X_train, y_train) #Fit
        
#Predict and score the model
y_test_preds = lm_model.predict(X_test) 
"The r-squared score for the model using only quantitative variables was {} on {} values.".format(r2_score(y_test, y_test_preds), len(y_test))

seattle_neighborhood = seattle_listing[['id', 'neighbourhood', 'price']]
# Remove all symbols from price
seattle_neighborhood['price'] = seattle_neighborhood['price'].str.replace(r'\D', '')
seattle_neighborhood['price'] = seattle_neighborhood['price'].astype(int)
seattle_neighborhood['price'] = seattle_neighborhood['price'] / 100

"""##Preparing Data
**Cleaning Data:**
"""

#Filter out neighborhood that only has a few listings less than 5
seattle_neighborhood = seattle_neighborhood[seattle_neighborhood.groupby('neighbourhood')['neighbourhood'].transform('size') > 5]

#Arrange neighborhood by average price
neighbourhood = seattle_neighborhood.groupby('neighbourhood')['price'].mean()
neighbourhood.sort_values(ascending=False, inplace=True)

"""##Data Modeling:"""

neighbourhood.plot(kind='bar', figsize=(16,10), title='Average Price per Neighborhood');

"""##Evaluate Results
For Seattle Listing, there is a clear correlation between neighborhood and price. For example, there is a vast difference between the top neighborhood and the bottom neighborhood. Portage Bay is more than 3 times the price as Olympic Hills. Also, Seattle provides a variety of pricing per neighborhood for different customer's budgets.

##Deploy
There is a clear correlation between Price and Neighborhood. For those who wants a good deal, look for Neighborhood like Rainier Beach, Dunlap, and Olympic Hills and avoid places like Portage Bay, Westlake, and Alki.
"""

